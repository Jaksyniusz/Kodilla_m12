{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 12.5. Podstawy Scikit-learn\n",
        "## Regresja logistyczna jako przykład używania biblioteki sklearn"
      ],
      "metadata": {
        "id": "VafhNf-nw7_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\"\"\"\n",
        "    LogisticRegression link - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
        "\n",
        "    Klasyfikator LogisticRegression znajduje się w bibliotece linear_model.\n",
        "    Ogólnie zasada jest następująca:\n",
        "    wszystkie klasyfikatory znajdują się w bibliotece sklarn.RODZINA_KLASYFIKATORÓW\n",
        "\n",
        "    przykładowo:\n",
        "    * wszystkie klasyfikatory liniowe znajdują się w bibliotece sklearn.linear_model\n",
        "    * wszystkie klasyfikatory bazujące na drzewach decyzyjnych w sklearn.tree\n",
        "    * wszystkie klasyfikatory bazujące na SVM w sklearn.svm\n",
        "    * ...\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "vfUQNb8HxIAE",
        "outputId": "7aeb49f0-d5bc-4a8e-a891-3b8a4cb83246"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    LogisticRegression link - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\\n\\n    Klasyfikator LogisticRegression znajduje się w bibliotece linear_model.\\n    Ogólnie zasada jest następująca:\\n    wszystkie klasyfikatory znajdują się w bibliotece sklarn.RODZINA_KLASYFIKATORÓW\\n\\n    przykładowo:\\n    * wszystkie klasyfikatory liniowe znajdują się w bibliotece sklearn.linear_model\\n    * wszystkie klasyfikatory bazujące na drzewach decyzyjnych w sklearn.tree\\n    * wszystkie klasyfikatory bazujące na SVM w sklearn.svm\\n    * ...\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier # drzewo decyzyjne -> tree\n",
        "from sklearn.svm import SVC # typ SVM, czyli po kropce jest svm\n",
        "from sklearn.neighbors import KNeighborsClassifier # model k najbliższych sąsiadów"
      ],
      "metadata": {
        "id": "o9GjPBbpxNUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf = LogisticRegression()\n",
        "\n",
        "\"\"\"\n",
        "    obiekt klasyfikatora tworzy się identycznie, jak każdy inny obiekt w Pythonie,\n",
        "    czyli poprzez wywołanie konstruktora\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "j7fJzw7Dxp8K",
        "outputId": "a2d655bb-9481-4e38-fdb7-6afb7e070cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    obiekt klasyfikatora tworzy się identycznie, jak każdy inny obiekt w Pythonie,\\n    czyli poprzez wywołanie konstruktora\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier  # drzewo decyzyjne -> tree\n",
        "from sklearn.svm import SVC  # typ SVM, czyli po kropce jest svm\n",
        "from sklearn.neighbors import KNeighborsClassifier  # model k najbliższych sąsiadów\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "svm_clf = SVC()  # Poprawiona nazwa zmiennej, aby była spójna z modelem\n",
        "knn_clf = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "IyZIdM-gx9g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_dG_eVTe599x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zastosujmy tę wiedzę w praktyce"
      ],
      "metadata": {
        "id": "55Jwo4cN5_R8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Prosty zbiór danych dostarczający losowe dane obiektów dwóch klas,\n",
        "# Aby przerobić na obiekty 3 klas, należy dodać kolejny element listy\n",
        "# weights, odpowiednio dopasować wagi, tak aby suma wynosiła 1.\n",
        "\n",
        "\"\"\"\n",
        "    Przykład tworzenia prostego zbioru danych\n",
        "\"\"\"\n",
        "def load_simple_classifier_dataset(weights=[0.5, 0.5]):\n",
        "    \"\"\"\n",
        "        Metoda generująca prosty zbiór danych\n",
        "\n",
        "        Argumenty:\n",
        "            weights - lista z udziałami obiektów każdej klasy w próbce,\n",
        "                      ich suma musi wynosić 1\n",
        "\n",
        "        Zwraca:\n",
        "            X - dane wejściowe dla modelu\n",
        "            y - true labels dla tych danych wejściowych\n",
        "    \"\"\"\n",
        "\n",
        "    X, y = make_classification(\n",
        "        n_samples=1000,\n",
        "        n_classes=len(weights),\n",
        "        n_informative=len(weights),\n",
        "        weights=weights,\n",
        "        flip_y=0,\n",
        "        random_state=1\n",
        "    )\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "hFFYul9Vyb9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Przykład ładowania trudniejszego zbioru danych\n",
        "\"\"\"\n",
        "def load_mnist_data():\n",
        "    \"\"\"\n",
        "        Zwraca:\n",
        "            X - dane\n",
        "            y - target labels\n",
        "            target_names - labels do tego zbioru\n",
        "    \"\"\"\n",
        "    mnist_data = fetch_openml('mnist_784', version=1)\n",
        "    print(\"keys of data dictionary: \", mnist_data.keys())\n",
        "\n",
        "    X, y = mnist_data['data'], mnist_data['target']\n",
        "\n",
        "    return X, y, mnist_data.target_names"
      ],
      "metadata": {
        "id": "oD8CqiaM6FWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# załadowanie zbioru danych\n",
        "x, y = load_simple_classifier_dataset()\n",
        "\n",
        "# stworzenie klasyfikatora\n",
        "clf = LogisticRegression()\n",
        "\n",
        "print(\"fitting - training...\")\n",
        "clf.fit(x, y)\n",
        "\n",
        "print(\"predicting...\")\n",
        "y_pred = clf.predict(x)\n",
        "\n",
        "# wypisujemy wartości dla pierwszych 10 predykcji\n",
        "\n",
        "print(\"true values \", y[:10])\n",
        "print(\"predicted   \", y_pred[:10])\n",
        "\n",
        "print(\"scoring...\")\n",
        "\n",
        "clf_score = clf.score(x, y)\n",
        "print(\"score = \", clf_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq1FCjcl6jfb",
        "outputId": "a92b2a77-b6f9-428c-c352-3b02dba70dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting - training...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 1 1 0 0 0]\n",
            "predicted    [0 1 0 0 0 1 1 0 0 0]\n",
            "scoring...\n",
            "score =  0.854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier # drzewo decyzyjne -> tree\n",
        "from sklearn.svm import SVC # typ SVM, czyli po kropce jest svm\n",
        "from sklearn.neighbors import KNeighborsClassifier # model k najbliższych sąsiadów\n",
        "\n",
        "# stworzenie klasyfikatorów\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "svc_clf = SVC()\n",
        "knn_clf = KNeighborsClassifier()\n",
        "\n",
        "# stworzenie pełnego pipeline'u ML\n",
        "x, y = load_simple_classifier_dataset()\n",
        "\n",
        "# wrzucamy wszystkie klasyfikatory do jednej listy\n",
        "klasyfikatory = [dt_clf, svc_clf, knn_clf]\n",
        "\n",
        "for clf in klasyfikatory:\n",
        "    print(\"--------------\")\n",
        "    print(\"fitting - training...\")\n",
        "    clf.fit(x, y)\n",
        "\n",
        "    print(\"predicting...\")\n",
        "    y_pred = clf.predict(x)\n",
        "\n",
        "    # wpisujemy wartości dla pierwszych 10 predykcji\n",
        "\n",
        "    print(\"true values \", y[:10])\n",
        "    print(\"predicted   \", y_pred[:10])\n",
        "\n",
        "    print(\"scoring...\")\n",
        "\n",
        "    clf_score = clf.score(x, y)\n",
        "    print(\"score = \", clf_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDteW3oG6tfa",
        "outputId": "2548db19-52e2-46fa-e2a0-ba563d064a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------\n",
            "fitting - training...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 1 1 0 0 0]\n",
            "predicted    [0 0 0 0 0 1 1 0 0 0]\n",
            "scoring...\n",
            "score =  1.0\n",
            "--------------\n",
            "fitting - training...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 1 1 0 0 0]\n",
            "predicted    [0 1 0 0 0 1 1 0 0 0]\n",
            "scoring...\n",
            "score =  0.918\n",
            "--------------\n",
            "fitting - training...\n",
            "predicting...\n",
            "true values  [0 0 0 0 0 1 1 0 0 0]\n",
            "predicted    [0 1 0 0 0 1 1 0 0 0]\n",
            "scoring...\n",
            "score =  0.865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#importujemy train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\"\"\"\n",
        "Dane wejściowe:\n",
        "    X - wejście do naszego modelu, które chcemy podzielić.\n",
        "        Może to być tablica NumPy, lista Pythona, dataframe z Pandas itp.\n",
        "    y - true labels, które chcemy podzielić wraz z wejściem.\n",
        "        Chcemy mieć taki sam podział wejść i odpowiadających im wyjść, prawda?\n",
        "\n",
        "    test_size    - jaki procent danych ma być użyty do testowania, 0.33 == 33%\n",
        "    random_state - ustalenie tej wartości gwarantuje zawsze taki sam podział.\n",
        "                   Przydatne przy porównywaniu klasyfikatorów na tych samych danych\n",
        "\n",
        "Dane wyjściowe:\n",
        "    X_train, X_test - wejścia odpowiednio dla treningu i testowania\n",
        "    y_train, y_test - wyjścia odpowiednio da treningu i testowania odpowiadające\n",
        "                      kolejnością wejściom (relacja wejście wyjście jest zachowana)\n",
        "\"\"\"\n",
        "\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "    train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "EjjYqefP-EXM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ćwiczenie"
      ],
      "metadata": {
        "id": "wj_w5Fgo-SNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier  # drzewo decyzyjne -> tree\n",
        "\n",
        "# Zakładam, że funkcja load_simple_classifier_dataset() jest zdefiniowana gdzieś wcześniej\n",
        "x, y = load_simple_classifier_dataset()\n",
        "\n",
        "# Podział danych na zbiór treningowy i testowy\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
        "\n",
        "# Inicjalizacja modeli\n",
        "clf = DecisionTreeClassifier()  # model uczony na zbiorze treningowym\n",
        "clf_2 = DecisionTreeClassifier()  # model uczony na całym zbiorze danych\n",
        "\n",
        "print(\"fitting - training...\")\n",
        "clf.fit(X_train, y_train)  # Trenowanie modelu na zbiorze treningowym\n",
        "\n",
        "print(\"training on whole dataset...\")\n",
        "clf_2.fit(x, y)  # Trenowanie modelu na całym zbiorze danych\n",
        "\n",
        "print(\"predicting...\")\n",
        "y_pred = clf.predict(X_test)  # Przewidywanie na zbiorze testowym\n",
        "\n",
        "# Wypisanie wartości dla pierwszych 10 predykcji\n",
        "print(\"true values  \", y_test[:10])  # Rzeczywiste wartości (ze zbioru testowego)\n",
        "print(\"predicted    \", y_pred[:10])  # Przewidywane wartości\n",
        "\n",
        "print(\"scoring...\")\n",
        "\n",
        "# Ocena modelu na zbiorze treningowym\n",
        "clf_score = clf.score(X_train, y_train)\n",
        "print(\"Train score = \", clf_score)\n",
        "\n",
        "# Ocena modelu na zbiorze testowym\n",
        "clf_score = clf.score(X_test, y_test)\n",
        "print(\"Test score = \", clf_score)\n",
        "\n",
        "# Ocena modelu na całym zbiorze danych\n",
        "clf_score = clf_2.score(x, y)\n",
        "print(\"whole set score = \", clf_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWEC1QgA-Yrk",
        "outputId": "3bbc4d0a-7977-4692-a7d7-b0ea3f60be8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting - training...\n",
            "training on whole dataset...\n",
            "predicting...\n",
            "true values   [1 0 1 0 0 0 0 1 1 1]\n",
            "predicted     [1 0 1 0 0 0 0 1 1 1]\n",
            "scoring...\n",
            "Train score =  1.0\n",
            "Test score =  0.825\n",
            "whole set score =  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Widać, iż w przypadku klasyfikatora DecissionTreeClassifier mamy do czynienia z overfittingiem. Dla danych treningowych mamy metrykę równą 1.0! Z kolei dla danych testowych mamy metrykę wyraźnie mniejszą, czyli coś jest nie tak.\n",
        "\n",
        "Typowy przykład overfittingu występuje, gdy model dla danych testowych idealnie się dopasował, natomiast dla danych, których nie \"widział\" przewiduje \"koślawo\".\n",
        "\n",
        "Podczas trenowania modelu na wspólnych danych widać, iż metryka jest znacznie bliższa 1.0, niż gdy model był szkolony na danych treningowych i testowany na testowych (osobnych). Za pomocą train_test_split można zatem wykryć wady naszego modelu. Otrzymujemy metrykę dla danych, których nasz model nie \"widział\". Jest to bardziej wiarygodne niż sprawdzanie modelu na tych samych danych, na których go szkoliliśmy.\n",
        "\n",
        "Wracając do porównania do egzaminu. Bardziej wartościowe dla nas jest zdanie egzaminu z języka francuskiego, nie znając wcześniej pytań, gdyż wiemy, że zasłużyliśmy na ocenę i że wyjeżdżając na wakacje dogadamy się z Francuzami. Natomiast odpowiadając na te same pytania, które wkuliśmy na pamięć, podczas egzaminu możemy nie mieć pojęcia o języku francuskim, a i tak zdamy na 100%. Jednak wakacje zweryfikują fakt, że nie potrafimy nawet kupić bułki w piekarni.\n",
        "\n",
        "Tym jest właśnie overfitting – model uzyskuje super wynik, ale dla danych które \"widział\", natomiast dla nowych danych nie jest w stanie nic przewidzieć prawidłowo. Zauważ, że tutaj wynik poniżej 0.5 jest słabszy niż wybieranie na chybił trafił!."
      ],
      "metadata": {
        "id": "lnDLnnAO_Kbp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d_cLSBUrANHz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}